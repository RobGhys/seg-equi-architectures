{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:48.239333Z",
     "start_time": "2025-03-12T10:11:46.950529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch"
   ],
   "id": "ad44b71e53f0368e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:48.248750Z",
     "start_time": "2025-03-12T10:11:48.245506Z"
    }
   },
   "cell_type": "code",
   "source": "small = False",
   "id": "54ce0899db9ce903",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:48.323798Z",
     "start_time": "2025-03-12T10:11:48.311203Z"
    }
   },
   "source": [
    "output_root_dir = '' \n",
    "weights_root_dir = '/home/rob/Documents/3_projects/bench/_results/ten_percent'\n",
    "#weights_root_dir = '/home/rob/Documents/3_projects/bench/_results/'\n",
    "model_names = ['C16']\n",
    "\n",
    "#model_names = ['UNet_e2cnn', 'UNet_vanilla', 'C8', 'D4']\n",
    "#dataset_names = ['coco']\n",
    "dataset_names = ['coco', 'isaid']\n",
    "final_epochs = {'isaid': 249, 'coco': 199}\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:48.371974Z",
     "start_time": "2025-03-12T10:11:48.360008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "settings_small = {\n",
    "    \"isaid\": {\n",
    "        \"name\": \"isaid\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/isaid\",\n",
    "        \"multiclass_palette_path\" : \"/home/rob/Documents/3_projects/bench/isaid/isaid_mask_palette.json\",\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 16,\n",
    "        \"num_workers\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"batch_size\": 4,\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 6,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 23,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C16\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C16\": {\n",
    "                \"lbda\": 1111,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C16\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"coco\": {\n",
    "        \"name\": \"coco\",\n",
    "        \"annotation_file\": \"/home/rob/Documents/3_projects/bench/coco/output/tmp_data/stuff_annotations_trainval2017/annotations/stuff_train2017.json\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/coco/output\",\n",
    "        \"multiclass_palette_path\": None,\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 93,\n",
    "        \"num_workers\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"batch_size\": 4,\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"lr\": 0.001,\n",
    "            \"num_epochs\": 200,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 6,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 23,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C16\": {\n",
    "                \"lbda\": 1111,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C16\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "9ed0bb1f2a582822",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:48.431752Z",
     "start_time": "2025-03-12T10:11:48.422232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "settings_large = {\n",
    "    \"isaid\": {\n",
    "        \"name\": \"isaid\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/isaid\",\n",
    "        \"multiclass_palette_path\" : \"/home/rob/Documents/3_projects/bench/isaid/isaid_mask_palette.json\",\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 16,\n",
    "        \"shuffle\": True,\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"num_workers\": 32,\n",
    "        \"batch_size\": 4,\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 1.25,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 4.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C16\": {\n",
    "                \"lbda\": 9.5,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C16\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"coco\": {\n",
    "        \"name\": \"coco\",\n",
    "        \"annotation_file\": \"/home/rob/Documents/3_projects/bench/coco/output/tmp_data/stuff_annotations_trainval2017/annotations/stuff_train2017.json\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/coco/output\",\n",
    "        \"multiclass_palette_path\": None,\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 93,\n",
    "        \"num_workers\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"batch_size\": 4,\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"lr\": 0.001,\n",
    "            \"num_epochs\": 200,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 1.25,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 4.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C16\": {\n",
    "                \"lbda\": 9.5,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C16\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "977f1dfdf9c38a7d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:48.468782Z",
     "start_time": "2025-03-12T10:11:48.464855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if small:\n",
    "    print('small')\n",
    "    settings = settings_small\n",
    "    weights_loc = os.path.join(weights_root_dir, 'small_models')\n",
    "else:\n",
    "    print('large')\n",
    "    settings = settings_large\n",
    "    weights_loc = os.path.join(weights_root_dir, 'large_models')\n",
    "\n",
    "print(f'weights loc is : {weights_loc}')"
   ],
   "id": "783b2624d86c1c72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large\n",
      "weights loc is : /home/rob/Documents/3_projects/bench/_results/ten_percent/large_models\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:49.200849Z",
     "start_time": "2025-03-12T10:11:48.522093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import e2cnn.nn as e2_nn\n",
    "from e2cnn import gspaces\n",
    "from models import *\n",
    "from building_blocks import *\n",
    "\n",
    "\n",
    "def getModel(model_name, settings):\n",
    "\n",
    "    if model_name == 'UNet_vanilla':\n",
    "        acti = nn.ReLU\n",
    "        acti_kwargs = settings['models'][model_name]['acti_kwargs']\n",
    "    elif model_name == 'UNet_e2cnn' or model_name == 'C8' or model_name == 'D4' or model_name == 'C16':\n",
    "        acti = e2_nn.ReLU\n",
    "        acti_kwargs = settings['models']['UNet_e2cnn']['acti_kwargs']\n",
    "\n",
    "    if model_name == 'UNet_vanilla':\n",
    "        model = UNet_vanilla(settings['in_channels'], settings['n_classes'], \n",
    "                             lbda=settings['models'][model_name]['lbda'], acti=acti, \n",
    "                             acti_kwargs=acti_kwargs, bilinear=settings['models'][model_name]['bilinear'],\n",
    "                             kernel_size=settings['models'][model_name]['kernel_size'])\n",
    "        n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        return model, n_params\n",
    "\n",
    "    elif model_name == 'UNet_e2cnn' or model_name == 'C8' or model_name == 'D4' or model_name == 'C16':\n",
    "        if model_name == 'UNet_e2cnn':\n",
    "            gspace = gspaces.Rot2dOnR2(N=4)\n",
    "            lbda = settings['models']['UNet_e2cnn']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'C4 mother')\n",
    "        elif model_name == 'C8':\n",
    "            gspace = gspaces.Rot2dOnR2(N=8)\n",
    "            lbda = settings['models']['C8']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'C8 brother')\n",
    "        elif model_name == 'D4':\n",
    "            gspace = gspaces.FlipRot2dOnR2(N=4)\n",
    "            lbda = settings['models']['D4']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'D4 sister')\n",
    "        elif model_name == 'C16':\n",
    "            gspace = gspaces.Rot2dOnR2(N=16)\n",
    "            lbda = settings['models']['C16']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'C16 father')\n",
    "        else:\n",
    "            raise NotImplementedError(\"gspace should be C4, C8 or D4 or C16\")\n",
    "        model = UNet_e2cnn(settings['in_channels'], settings['n_classes'],\n",
    "                           lbda=lbda, acti=acti, \n",
    "                           acti_kwargs=acti_kwargs, bilinear=settings['models']['UNet_e2cnn']['bilinear'],\n",
    "                           kernel_size=settings['models']['UNet_e2cnn']['kernel_size'],\n",
    "                           mode=settings['models']['UNet_e2cnn']['mode'], gspace=gspace)\n",
    "        n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        return model, n_params\n"
   ],
   "id": "91bb8528a424bc44",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:49.835331Z",
     "start_time": "2025-03-12T10:11:49.208646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "#meanIou -> IoU\n",
    "def get_segmentation_metrics(num_classes, device):\n",
    "    return {\n",
    "        'IoU': torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes, average='macro').to(device),\n",
    "        'Dice': torchmetrics.Dice(num_classes=num_classes, average='macro').to(device),\n",
    "        'Pixel Accuracy': torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='micro').to(device),\n",
    "        'Mean Accuracy': torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro').to(device),\n",
    "        'Frequency Weighted IoU': torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes, average='weighted').to(device),\n",
    "        'Recall': torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='macro').to(device),\n",
    "        'Precision': torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='macro').to(device)\n",
    "    }\n",
    "\n",
    "def run_inference(model, data_loader, device, num_classes):\n",
    "    eval_metrics = get_segmentation_metrics(num_classes, device)\n",
    "    all_results = {metric_name: [] for metric_name in eval_metrics.keys()}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(data_loader)):\n",
    "            imgs, masks = data['img'].to(device, dtype=torch.float32), data['mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "            masks_pred = model(imgs)\n",
    "\n",
    "            masks_pred_class = torch.argmax(masks_pred, dim=1)  # (N, H, W)\n",
    "\n",
    "            for name, metric in eval_metrics.items():\n",
    "                if name in ['IoU', 'Dice', 'Frequency Weighted IoU']:\n",
    "                    metric_result = metric(masks_pred, masks)\n",
    "                else:\n",
    "                    metric_result = metric(masks_pred_class, masks)\n",
    "                all_results[name].append(metric_result.item())\n",
    "\n",
    "    avg_results = {name: torch.tensor(values).mean().item() for name, values in all_results.items()}\n",
    "    return avg_results\n"
   ],
   "id": "bd0d25045b96f5b5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:11:49.847992Z",
     "start_time": "2025-03-12T10:11:49.845613Z"
    }
   },
   "cell_type": "code",
   "source": "errors_list = []",
   "id": "7b9428bd22d9a0f9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-12T10:11:49.888107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "#from src.Benchmarks.training.load_model import getModel\n",
    "from src.Benchmarks.training.load_data import get_data_loader\n",
    "# isaid small D4 & C8 --> 249 !!! \n",
    "\n",
    "results_dict = {}  # Initialize the main dictionary to hold all results\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f'***\\nProcessing {dataset_name}\\n***')\n",
    "    results_dict[dataset_name] = {}\n",
    "    settings_ds = settings[dataset_name] \n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f'Processing {dataset_name} with {model_name}')\n",
    "        results_dict[dataset_name][model_name] = {}\n",
    "        \n",
    "        for fold in range(5):\n",
    "            print(f'Processing fold {fold}')\n",
    "            output_path = os.path.join(output_root_dir, dataset_name, model_name, 'fold_' + str(fold))\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            _, test_loader = get_data_loader(settings_ds, fold)\n",
    "            model, _ = getModel(model_name, settings_ds)\n",
    "            model = model.to(device=device)\n",
    "        \n",
    "            checkpoint_path = os.path.join(weights_loc, dataset_name, model_name, f'fold_{fold}',\n",
    "                                           'checkpoint_epoch_{}.pth'.format(final_epochs[dataset_name])) \n",
    "            print(f'Checkpoint path is: {checkpoint_path}')\n",
    "            try:\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "                # print(type(checkpoint))\n",
    "                # if isinstance(checkpoint, dict):\n",
    "                #     print(checkpoint.keys())\n",
    "                model.load_state_dict(checkpoint)\n",
    "                model.eval() \n",
    "                \n",
    "                num_classes = settings_ds['n_classes']\n",
    "                results = run_inference(model, test_loader, device, num_classes)\n",
    "                \n",
    "                results_dict[dataset_name][model_name][f'fold_{fold}'] = results\n",
    "                \n",
    "                print(f\"Results for fold {fold}: {results}\")\n",
    "            except (FileNotFoundError, RuntimeError) as e:\n",
    "                check_fail = f'fold_{fold}&{model_name}&{dataset_name}'\n",
    "                print(f'!!! Could not load {check_fail}')\n",
    "                print(f'Error details: {str(e)}')\n",
    "                errors_list.append(check_fail)\n",
    "                print(f'!!! Could not load {check_fail}')\n",
    "                print(f'Error type: {type(e).__name__}')\n",
    "                print(f'Error message: {str(e)}')\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                errors_list.append(check_fail)\n",
    "        \n",
    "        print(f'!!! Finished ---> Processing {dataset_name} with {model_name}')\n",
    "\n",
    "json_name = 'final_inference_results_ten_percent_large_c16.json'\n",
    "#json_name = 'final_inference_results_large_c16.json'\n",
    "final_results_path = os.path.join(output_root_dir, json_name) \n",
    "with open(final_results_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)"
   ],
   "id": "bedc21f4324eb21f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Processing coco\n",
      "***\n",
      "Processing coco with C16\n",
      "Processing fold 0\n",
      "Percent subset is: 0.1\n",
      "loading annotations into memory...\n",
      "Done (t=8.72s)\n",
      "creating index...\n",
      "index created!\n",
      "lbda: 9.5\n",
      "C16 father\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  full_mask[mask] = norms.to(torch.uint8)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(errors_list)",
   "id": "e57db25075df5442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "72b4b91a5cefa91c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
