{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:47.678243Z",
     "start_time": "2024-10-24T06:46:47.674749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch"
   ],
   "id": "ad44b71e53f0368e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:47.700766Z",
     "start_time": "2024-10-24T06:46:47.697120Z"
    }
   },
   "cell_type": "code",
   "source": "small = False",
   "id": "54ce0899db9ce903",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:47.751940Z",
     "start_time": "2024-10-24T06:46:47.747071Z"
    }
   },
   "source": [
    "output_root_dir = '' \n",
    "weights_root_dir = '/home/rob/Documents/3_projects/bench/_results'\n",
    "\n",
    "model_names = ['D4']\n",
    "dataset_names = ['isaid']\n",
    "\n",
    "#model_names = ['UNet_vanilla', 'UNet_e2cnn', 'C8', 'D4']\n",
    "#dataset_names = ['isaid', 'coco']\n",
    "final_epochs = {'isaid': 109, 'coco': 199}\n",
    "#final_epochs = {'isaid': 239, 'coco': 199}\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:47.874884Z",
     "start_time": "2024-10-24T06:46:47.861816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "settings_small = {\n",
    "    \"isaid\": {\n",
    "        \"name\": \"isaid\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/isaid\",\n",
    "        \"multiclass_palette_path\" : \"/home/rob/Documents/3_projects/bench/isaid/isaid_mask_palette.json\",\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 16,\n",
    "        \"num_workers\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"batch_size\": 16,\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 6,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 23,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"coco\": {\n",
    "        \"name\": \"coco\",\n",
    "        \"annotation_file\": \"/home/rob/Documents/3_projects/bench/coco/output/tmp_data/stuff_annotations_trainval2017/annotations/stuff_train2017.json\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/coco/output\",\n",
    "        \"multiclass_palette_path\": None,\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 93,\n",
    "        \"num_workers\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"batch_size\": 16,\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"lr\": 0.001,\n",
    "            \"num_epochs\": 200,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 6,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 23,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 31,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "9ed0bb1f2a582822",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:47.927660Z",
     "start_time": "2024-10-24T06:46:47.918534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "settings_large = {\n",
    "    \"isaid\": {\n",
    "        \"name\": \"isaid\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/isaid\",\n",
    "        \"multiclass_palette_path\" : \"/home/rob/Documents/3_projects/bench/isaid/isaid_mask_palette.json\",\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 16,\n",
    "        \"shuffle\": True,\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"num_workers\": 32,\n",
    "        \"batch_size\": 16,\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 1.25,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 4.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"coco\": {\n",
    "        \"name\": \"coco\",\n",
    "        \"annotation_file\": \"/home/rob/Documents/3_projects/bench/coco/output/tmp_data/stuff_annotations_trainval2017/annotations/stuff_train2017.json\",\n",
    "        \"path\": \"/home/rob/Documents/3_projects/bench/coco/output\",\n",
    "        \"multiclass_palette_path\": None,\n",
    "        \"in_channels\": 3,\n",
    "        \"n_classes\": 93,\n",
    "        \"num_workers\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"transforms\": {\n",
    "            \"Resize\": [224, 224],\n",
    "            \"RandomCrop\": None,\n",
    "            \"flip\": True,\n",
    "            \"rot\": True,\n",
    "            \"Normalize\": [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]]\n",
    "        },\n",
    "        \"mask_type\": \"multiclass_semantic\",\n",
    "        \"batch_size\": 16,\n",
    "        \"models\": {\n",
    "            \"input_size\": 224,\n",
    "            \"lr\": 0.001,\n",
    "            \"num_epochs\": 200,\n",
    "            \"UNet_vanilla\": {\n",
    "                \"lbda\": 1.25,\n",
    "                \"bilinear\": True,\n",
    "                \"kernel_size\": 3,\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                }\n",
    "            },\n",
    "            \"UNet_e2cnn\": {\n",
    "                \"lbda\": 4.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"C8\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"C8\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            },\n",
    "            \"D4\": {\n",
    "                \"lbda\": 6.65,\n",
    "                \"bilinear\": True,\n",
    "                \"gspace\": \"D4\",\n",
    "                \"acti\": \"relu\",\n",
    "                \"acti_kwargs\": {\n",
    "                    \"inplace\": True\n",
    "                },\n",
    "                \"kernel_size\": 9,\n",
    "                \"mode\": \"pure\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "977f1dfdf9c38a7d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:47.978624Z",
     "start_time": "2024-10-24T06:46:47.974540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if small:\n",
    "    print('small')\n",
    "    settings = settings_small\n",
    "    weights_loc = os.path.join(weights_root_dir, 'small_models')\n",
    "else:\n",
    "    print('large')\n",
    "    settings = settings_large\n",
    "    weights_loc = os.path.join(weights_root_dir, 'large_models')"
   ],
   "id": "783b2624d86c1c72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:48.035735Z",
     "start_time": "2024-10-24T06:46:48.026035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import e2cnn.nn as e2_nn\n",
    "from e2cnn import gspaces\n",
    "from models import *\n",
    "from building_blocks import *\n",
    "\n",
    "\n",
    "def getModel(model_name, settings):\n",
    "\n",
    "    if model_name == 'UNet_vanilla':\n",
    "        acti = nn.ReLU\n",
    "        acti_kwargs = settings['models'][model_name]['acti_kwargs']\n",
    "    elif model_name == 'UNet_e2cnn' or model_name == 'C8' or model_name == 'D4':\n",
    "        acti = e2_nn.ReLU\n",
    "        acti_kwargs = settings['models']['UNet_e2cnn']['acti_kwargs']\n",
    "\n",
    "    if model_name == 'UNet_vanilla':\n",
    "        model = UNet_vanilla(settings['in_channels'], settings['n_classes'], \n",
    "                             lbda=settings['models'][model_name]['lbda'], acti=acti, \n",
    "                             acti_kwargs=acti_kwargs, bilinear=settings['models'][model_name]['bilinear'],\n",
    "                             kernel_size=settings['models'][model_name]['kernel_size'])\n",
    "        n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        return model, n_params\n",
    "\n",
    "    elif model_name == 'UNet_e2cnn' or model_name == 'C8' or model_name == 'D4':\n",
    "        if model_name == 'UNet_e2cnn':\n",
    "            gspace = gspaces.Rot2dOnR2(N=4)\n",
    "            lbda = settings['models']['UNet_e2cnn']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'C4 mother')\n",
    "        elif model_name == 'C8':\n",
    "            gspace = gspaces.Rot2dOnR2(N=8)\n",
    "            lbda = settings['models']['C8']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'C8 brother')\n",
    "        elif model_name == 'D4':\n",
    "            gspace = gspaces.FlipRot2dOnR2(N=4)\n",
    "            lbda = settings['models']['D4']['lbda']\n",
    "            print(f'lbda: {lbda}')\n",
    "            print(f'D4 sister')\n",
    "        else:\n",
    "            raise NotImplementedError(\"gspace should be C4, C8 or D4\")\n",
    "        model = UNet_e2cnn(settings['in_channels'], settings['n_classes'],\n",
    "                           lbda=lbda, acti=acti, \n",
    "                           acti_kwargs=acti_kwargs, bilinear=settings['models']['UNet_e2cnn']['bilinear'],\n",
    "                           kernel_size=settings['models']['UNet_e2cnn']['kernel_size'],\n",
    "                           mode=settings['models']['UNet_e2cnn']['mode'], gspace=gspace)\n",
    "        n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        return model, n_params\n"
   ],
   "id": "91bb8528a424bc44",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:48.088875Z",
     "start_time": "2024-10-24T06:46:48.080639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "#meanIou -> IoU\n",
    "def get_segmentation_metrics(num_classes, device):\n",
    "    return {\n",
    "        'IoU': torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes, average='macro').to(device),\n",
    "        'Dice': torchmetrics.Dice(num_classes=num_classes, average='macro').to(device),\n",
    "        'Pixel Accuracy': torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='micro').to(device),\n",
    "        'Mean Accuracy': torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro').to(device),\n",
    "        'Frequency Weighted IoU': torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes, average='weighted').to(device),\n",
    "        'Recall': torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='macro').to(device),\n",
    "        'Precision': torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='macro').to(device)\n",
    "    }\n",
    "\n",
    "def run_inference(model, data_loader, device, num_classes):\n",
    "    eval_metrics = get_segmentation_metrics(num_classes, device)\n",
    "    all_results = {metric_name: [] for metric_name in eval_metrics.keys()}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(data_loader)):\n",
    "            imgs, masks = data['img'].to(device, dtype=torch.float32), data['mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "            masks_pred = model(imgs)\n",
    "\n",
    "            masks_pred_class = torch.argmax(masks_pred, dim=1)  # (N, H, W)\n",
    "\n",
    "            for name, metric in eval_metrics.items():\n",
    "                if name in ['IoU', 'Dice', 'Frequency Weighted IoU']:\n",
    "                    metric_result = metric(masks_pred, masks)\n",
    "                else:\n",
    "                    metric_result = metric(masks_pred_class, masks)\n",
    "                all_results[name].append(metric_result.item())\n",
    "\n",
    "    avg_results = {name: torch.tensor(values).mean().item() for name, values in all_results.items()}\n",
    "    return avg_results\n"
   ],
   "id": "bd0d25045b96f5b5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:46:48.136390Z",
     "start_time": "2024-10-24T06:46:48.132671Z"
    }
   },
   "cell_type": "code",
   "source": "errors_list = []",
   "id": "7b9428bd22d9a0f9",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T06:48:31.671828Z",
     "start_time": "2024-10-24T06:46:48.193658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "#from src.Benchmarks.training.load_model import getModel\n",
    "from src.Benchmarks.training.load_data import get_data_loader\n",
    "# isaid small D4 & C8 --> 249 !!! \n",
    "\n",
    "results_dict = {}  # Initialize the main dictionary to hold all results\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f'***\\nProcessing {dataset_name}\\n***')\n",
    "    results_dict[dataset_name] = {}\n",
    "    settings_ds = settings[dataset_name] \n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f'Processing {dataset_name} with {model_name}')\n",
    "        results_dict[dataset_name][model_name] = {}\n",
    "        \n",
    "        for fold in range(5):\n",
    "            print(f'Processing fold {fold}')\n",
    "            output_path = os.path.join(output_root_dir, dataset_name, model_name, 'fold_' + str(fold))\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            _, test_loader = get_data_loader(settings_ds, fold)\n",
    "            model, _ = getModel(model_name, settings_ds)\n",
    "            model = model.to(device=device)\n",
    "        \n",
    "            checkpoint_path = os.path.join(weights_loc, dataset_name, model_name, f'fold_{fold}',\n",
    "                                           'checkpoint_epoch_{}.pth'.format(final_epochs[dataset_name])) \n",
    "            \n",
    "            try:\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "                model.load_state_dict(checkpoint)\n",
    "                model.eval() \n",
    "                \n",
    "                num_classes = settings_ds['n_classes']\n",
    "                results = run_inference(model, test_loader, device, num_classes)\n",
    "                \n",
    "                results_dict[dataset_name][model_name][f'fold_{fold}'] = results\n",
    "                \n",
    "                print(f\"Results for fold {fold}: {results}\")\n",
    "            except (FileNotFoundError, RuntimeError) as e:\n",
    "                check_fail = f'fold_{fold}&{model_name}&{dataset_name}'\n",
    "                print(f'!!! Could not load {check_fail}')\n",
    "                errors_list.append(check_fail)\n",
    "        \n",
    "        print(f'!!! Finished ---> Processing {dataset_name} with {model_name}')\n",
    "\n",
    "json_name = 'final_inference_results_large__2.json'\n",
    "final_results_path = os.path.join(output_root_dir, json_name) \n",
    "with open(final_results_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)"
   ],
   "id": "bedc21f4324eb21f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Processing isaid\n",
      "***\n",
      "Processing isaid with D4\n",
      "Processing fold 0\n",
      "lbda: 6.65\n",
      "D4 sister\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:20,  1.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 34\u001B[0m\n\u001B[1;32m     31\u001B[0m model\u001B[38;5;241m.\u001B[39meval() \n\u001B[1;32m     33\u001B[0m num_classes \u001B[38;5;241m=\u001B[39m settings_ds[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_classes\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 34\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mrun_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m results_dict[dataset_name][model_name][\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfold_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m results\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResults for fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[28], line 28\u001B[0m, in \u001B[0;36mrun_inference\u001B[0;34m(model, data_loader, device, num_classes)\u001B[0m\n\u001B[1;32m     24\u001B[0m imgs, masks \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32), data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[1;32m     26\u001B[0m masks \u001B[38;5;241m=\u001B[39m masks\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m masks_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m masks_pred_class \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(masks_pred, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# (N, H, W)\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, metric \u001B[38;5;129;01min\u001B[39;00m eval_metrics\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/src/U-Net/models.py:162\u001B[0m, in \u001B[0;36mUNet_e2cnn.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    161\u001B[0m     x1, x1_out_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minc(x)\n\u001B[0;32m--> 162\u001B[0m     x2, x2_out_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdown1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     x3, x3_out_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown2(x2)\n\u001B[1;32m    164\u001B[0m     x4, x4_out_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown3(x3)\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/src/U-Net/building_blocks.py:176\u001B[0m, in \u001B[0;36mDown_e2cnn.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/src/U-Net/building_blocks.py:118\u001B[0m, in \u001B[0;36mDoubleConv_e2cnn.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, e2_nn\u001B[38;5;241m.\u001B[39mgeometric_tensor\u001B[38;5;241m.\u001B[39mGeometricTensor):\n\u001B[1;32m    115\u001B[0m     x \u001B[38;5;241m=\u001B[39m e2_nn\u001B[38;5;241m.\u001B[39mGeometricTensor(\n\u001B[1;32m    116\u001B[0m         x, e2_nn\u001B[38;5;241m.\u001B[39mFieldType(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgspace, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_channels \u001B[38;5;241m*\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgspace\u001B[38;5;241m.\u001B[39mtrivial_repr])\n\u001B[1;32m    117\u001B[0m     )\n\u001B[0;32m--> 118\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdouble_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_type\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/seg-equi-architectures/.venv/lib/python3.11/site-packages/e2cnn/nn/modules/batchnormalization/inner.py:140\u001B[0m, in \u001B[0;36mInnerBatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    135\u001B[0m batchnorm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_norm_[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m contiguous:\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;66;03m# if the fields were contiguous, we can use slicing\u001B[39;00m\n\u001B[1;32m    139\u001B[0m     output[:, indices[\u001B[38;5;241m0\u001B[39m]:indices[\u001B[38;5;241m1\u001B[39m], :, :] \u001B[38;5;241m=\u001B[39m batchnorm(\n\u001B[0;32m--> 140\u001B[0m         \u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m:\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     )\u001B[38;5;241m.\u001B[39mview(b, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, h, w)\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;66;03m# otherwise we have to use indexing\u001B[39;00m\n\u001B[1;32m    144\u001B[0m     output[:, indices, :, :] \u001B[38;5;241m=\u001B[39m batchnorm(\n\u001B[1;32m    145\u001B[0m         \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mtensor[:, indices, :, :]\u001B[38;5;241m.\u001B[39mview(b, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, s, h, w)\n\u001B[1;32m    146\u001B[0m     )\u001B[38;5;241m.\u001B[39mview(b, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, h, w)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(errors_list)",
   "id": "e57db25075df5442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Not ok : C4 for coco small /// D4 for isaid large",
   "id": "76e02155c0f65a71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# not ok :",
   "id": "f9eb35d031be5e69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LARGE \n",
    "# ['fold_0&D4&isaid', 'fold_1&D4&isaid', 'fold_2&D4&isaid', 'fold_3&D4&isaid', 'fold_4&D4&isaid', 'fold_0&C8&coco', 'fold_1&C8&coco', 'fold_2&C8&coco', 'fold_3&C8&coco', 'fold_4&C8&coco']#"
   ],
   "id": "57ab53964189bbfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SMALL\n",
    "#['fold_0&UNet_e2cnn&coco', 'fold_1&UNet_e2cnn&coco', 'fold_2&UNet_e2cnn&coco', 'fold_3&UNet_e2cnn&coco', 'fold_4&UNet_e2cnn&coco']"
   ],
   "id": "e3649aa56812114b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "69a6d23cd5f8bb16",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
