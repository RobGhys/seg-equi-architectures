{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.350332Z",
     "start_time": "2024-10-23T07:50:30.347114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import pandas as pd"
   ],
   "id": "c506566519757954",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.401015Z",
     "start_time": "2024-10-23T07:50:30.395028Z"
    }
   },
   "source": [
    "def calculate_mean_confidence_interval(data, confidence=0.95):\n",
    "    mean = np.mean(data)\n",
    "    n = len(data)\n",
    "    stderr = stats.sem(data)\n",
    "    h = stderr * stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "    return mean, h"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.449980Z",
     "start_time": "2024-10-23T07:50:30.445571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_size = 'large'\n",
    "input_path = f'final_inference_results_{model_size}.json'\n",
    "with open(input_path, 'r') as f:\n",
    "    original_results = json.load(f)"
   ],
   "id": "70a4d91e77965bb2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.521507Z",
     "start_time": "2024-10-23T07:50:30.495012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the new dictionary to hold the mean and confidence intervals\n",
    "aggregated_results = {}\n",
    "\n",
    "# Iterate through each dataset and model to compute mean and confidence intervals\n",
    "for dataset_name, models in original_results.items():\n",
    "    aggregated_results[dataset_name] = {}\n",
    "    for model_name, folds in models.items():\n",
    "        metrics_aggregated = {}\n",
    "        for fold_name, metrics in folds.items():\n",
    "            for metric_name, value in metrics.items():\n",
    "                if metric_name not in metrics_aggregated:\n",
    "                    metrics_aggregated[metric_name] = []\n",
    "                metrics_aggregated[metric_name].append(value)\n",
    "\n",
    "        # Calculate mean and 95% confidence interval for each metric\n",
    "        metrics_summary = {}\n",
    "        for metric_name, values in metrics_aggregated.items():\n",
    "            mean, ci = calculate_mean_confidence_interval(values)\n",
    "            metrics_summary[metric_name] = {\n",
    "                \"mean\": mean,\n",
    "                \"95%_CI\": ci\n",
    "            }\n",
    "\n",
    "        aggregated_results[dataset_name][model_name] = metrics_summary\n",
    "\n",
    "# Save the aggregated results to a new JSON file\n",
    "output_path = 'aggregated_inference_results.json'  # Adjust path if needed\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(aggregated_results, f, indent=4)"
   ],
   "id": "58b12a790f6263f0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.553472Z",
     "start_time": "2024-10-23T07:50:30.548963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "for dataset_name, models in aggregated_results.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        row = {\"Dataset\": dataset_name, \"Model\": model_name}\n",
    "        for metric_name, summary in metrics.items():\n",
    "            mean = summary[\"mean\"]\n",
    "            ci = summary[\"95%_CI\"]\n",
    "            row[f\"{metric_name}\"] = f\"{mean:.4f} ± {ci:.4f}\"\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ],
   "id": "da641b6cf18c0976",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.603661Z",
     "start_time": "2024-10-23T07:50:30.597362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_isaid = df.loc[df['Dataset'] == 'isaid']\n",
    "\n",
    "print(df_isaid)"
   ],
   "id": "23aea68e6d80442f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset         Model              IoU             Dice   Pixel Accuracy  \\\n",
      "0   isaid  UNet_vanilla  0.4821 ± 0.0175  0.5373 ± 0.0186  0.9763 ± 0.0027   \n",
      "1   isaid    UNet_e2cnn  0.4307 ± 0.0160  0.4821 ± 0.0180  0.9747 ± 0.0024   \n",
      "2   isaid            C8  0.4457 ± 0.0144  0.4980 ± 0.0155  0.9756 ± 0.0026   \n",
      "3   isaid            D4              NaN              NaN              NaN   \n",
      "\n",
      "     Mean Accuracy Frequency Weighted IoU           Recall        Precision  \n",
      "0  0.5268 ± 0.0165        0.9578 ± 0.0043  0.5268 ± 0.0165  0.5924 ± 0.0200  \n",
      "1  0.4714 ± 0.0174        0.9550 ± 0.0041  0.4714 ± 0.0174  0.5355 ± 0.0201  \n",
      "2  0.4876 ± 0.0163        0.9567 ± 0.0043  0.4876 ± 0.0163  0.5516 ± 0.0147  \n",
      "3              NaN                    NaN              NaN              NaN  \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.659923Z",
     "start_time": "2024-10-23T07:50:30.654117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_coco = df.loc[df['Dataset'] == 'coco']\n",
    "\n",
    "print(df_coco)"
   ],
   "id": "bf7be7a399ddb830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset         Model              IoU             Dice   Pixel Accuracy  \\\n",
      "4    coco  UNet_vanilla  0.1789 ± 0.0013  0.2276 ± 0.0017  0.6888 ± 0.0019   \n",
      "5    coco    UNet_e2cnn  0.1822 ± 0.0022  0.2277 ± 0.0027  0.6781 ± 0.0021   \n",
      "6    coco            C8  0.1829 ± 0.0042  0.2276 ± 0.0052  0.6780 ± 0.0024   \n",
      "7    coco            D4              NaN              NaN              NaN   \n",
      "\n",
      "     Mean Accuracy Frequency Weighted IoU           Recall        Precision  \n",
      "4  0.2380 ± 0.0025        0.5629 ± 0.0056  0.2380 ± 0.0025  0.2834 ± 0.0048  \n",
      "5  0.2413 ± 0.0023        0.5484 ± 0.0027  0.2413 ± 0.0023  0.2810 ± 0.0041  \n",
      "6  0.2416 ± 0.0060        0.5479 ± 0.0069  0.2416 ± 0.0060  0.2808 ± 0.0037  \n",
      "7              NaN                    NaN              NaN              NaN  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T07:50:30.709117Z",
     "start_time": "2024-10-23T07:50:30.706120Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a342d2c7232bedab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
